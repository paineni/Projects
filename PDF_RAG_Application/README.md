# ğŸ“„ PDF Q&A System with LangChain, FAISS & HuggingFace Embeddings ğŸ¤–ğŸ”  
**(Retrieval-Augmented Generation Application)**

![Python](https://img.shields.io/badge/Python-3.8%2B-blue)
![RAG](https://img.shields.io/badge/RAG-Retrieval%20Augmented%20Generation-blueviolet)
![LLMs](https://img.shields.io/badge/LLMs-Large%20Language%20Models-critical)
![GenAI](https://img.shields.io/badge/AI-Type%20-%20Generative%20AI-lightgrey)
![FAISS](https://img.shields.io/badge/Vector%20DB-FAISS-blue)
![GROQ](https://img.shields.io/badge/LLM%20Provider-GROQ-orange)
![LLaMA3](https://img.shields.io/badge/Model-LLaMA3-red)
![HuggingFace](https://img.shields.io/badge/Embeddings-HuggingFace-yellow)
![LangChain](https://img.shields.io/badge/Framework-LangChain-9cf)
![Streamlit](https://img.shields.io/badge/UI-Streamlit-brightgreen)
![Deploy](https://img.shields.io/badge/Deployment-Streamlit%20Cloud%20or%20Spaces-success)
![License](https://img.shields.io/badge/License-MIT-green)
![Open Source Love](https://img.shields.io/badge/%E2%9D%A4%EF%B8%8F-Open%20Source-pink)

This repository implements a **Retrieval-Augmented Generation (RAG)** pipeline to enable natural language Q&A over PDF documents. It combines semantic search using FAISS with large language models (LLaMA3 via GROQ API) for generating context-aware answers. Built using **LangChain**, this app serves as an interactive and lightweight tool to explore knowledge locked in PDFs.

---

## ğŸ“š Key Features

- ğŸ” **RAG Architecture**: Combines document retrieval (FAISS + HuggingFace embeddings) with LLM-based generation (LLaMA3) to provide grounded answers.
- ğŸ“„ **PDF Loader**: Automatically scans and ingests all PDFs from a directory.
- ğŸ§© **Chunking & Embedding**: Splits large documents into manageable segments and embeds them using HuggingFaceâ€™s `all-MiniLM-L6-v2` model.
- âš¡ **Vector Store with FAISS**: Efficient semantic similarity search over embedded chunks.
- ğŸ§  **Context-Aware LLM Responses**: LLaMA3 generates answers strictly based on the retrieved document context using LangChainâ€™s `stuff` document chain.
- ğŸ–¥ï¸ **Streamlit Frontend**: Intuitive UI for embedding documents and querying in real time.
- ğŸ“ **Document Traceability**: View the exact document chunks that contributed to the final response.

---

ğŸ”§ Installation Steps
Clone the repository:

bash
Copy
Edit
git clone https://github.com/paineni/Projects.git
cd Projects/pdf_rag_app
Create and activate a virtual environment:

bash
Copy
Edit
python -m venv venv
# For Windows:
venv\Scripts\activate
# For macOS/Linux:
source venv/bin/activate
Install the dependencies:

bash
Copy
Edit
pip install -r requirements.txt
Create a .env file and add your credentials:

ini
Copy
Edit
GROQ_API=your_groq_api_key
HF_TOKEN=your_huggingface_token
Place your PDF files inside the research_papers/ folder.

ğŸ§‘â€ğŸ’» Usage
Launch the App

bash
Copy
Edit
streamlit run app.py
Embed PDFs

Click the "Document Embedding" button in the UI to create the FAISS vector store.

Ask Questions

Type any query. The app will:

Retrieve relevant document chunks

Pass them to the LLM

Generate a grounded answer

View Source Chunks

Expand the â€œDocuments Similarity Searchâ€ section to inspect supporting document text.

ğŸ” Example Use Cases
ğŸ“š Research paper assistant

ğŸ“„ Resume Q&A bot

âš–ï¸ Legal document helper

ğŸ¢ Company knowledge base search

ğŸ¤ Contributing
PRs and suggestions are welcome!
Letâ€™s improve this together â€” from LLM integration to UI enhancements.
