{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "from detectron2.structures import BoxMode\n",
    "import sys\n",
    "\n",
    "# Some basic setup:\n",
    "# Setup detectron2 logger\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from matplotlib import pyplot as plt\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing samples...\n",
      " 100% |█████████████████| 120/120 [41.2ms elapsed, 0s remaining, 2.9K samples/s]      \n",
      "Import complete\n"
     ]
    }
   ],
   "source": [
    "dataset = fo.Dataset.from_dir(\n",
    "    dataset_dir=\"prepared\",\n",
    "    dataset_type=fo.types.FiftyOneDataset,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(dataset):\n",
    "        # Tag test images.\n",
    "    testset_view = dataset.take(round(0.1 * len(dataset)), seed=42)\n",
    "        \n",
    "            \n",
    "\n",
    "    testset_view.tag_samples(\"test\")\n",
    "\n",
    "    # Split remaining images into train and valid.\n",
    "    nontestset_view = dataset.match_tags(\"test\", bool=False)\n",
    "    validset_view = nontestset_view.take(\n",
    "        round(0.2 * len(nontestset_view)), seed=42\n",
    "    )\n",
    "    validset_view.tag_samples(\"valid\")\n",
    "    nontestset_view.match_tags(\"valid\", bool=False).tag_samples(\"train\")\n",
    "    dataset.save()\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cocoa', 'invalid']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.default_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fiftyone_dicts(dataset):\n",
    "    dataset.compute_metadata()\n",
    "\n",
    "    dataset_dicts = []\n",
    "    for sample in dataset:\n",
    "        height = sample.metadata[\"height\"]\n",
    "        width = sample.metadata[\"width\"]\n",
    "        record = {}\n",
    "        record[\"file_name\"] = sample.filepath\n",
    "        record[\"image_id\"] = sample.id\n",
    "        record[\"height\"] = height\n",
    "        record[\"width\"] = width\n",
    "\n",
    "        objs = []\n",
    "        for det in sample.ground_truth.detections:\n",
    "            tlx, tly, w, h = det.bounding_box\n",
    "            bbox = [int(tlx*width), int(tly*height), int(w*width), int(h*height)]\n",
    "            \n",
    "            obj = {\n",
    "                \"bbox\": bbox,\n",
    "                \"bbox_mode\": BoxMode.XYWH_ABS,\n",
    "                \"category_id\": dataset.default_classes.index(det.label),\n",
    "            }\n",
    "            objs.append(obj)\n",
    "\n",
    "        record[\"annotations\"] = objs\n",
    "        dataset_dicts.append(record)\n",
    "\n",
    "    return dataset_dicts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in [\"train\", \"valid\"]:\n",
    "    view = dataset.match_tags(d)\n",
    "    DatasetCatalog.register(\"fiftyone_\" + d, lambda view=view: get_fiftyone_dicts(view))\n",
    "    MetadataCatalog.get(\"fiftyone_\" + d).thing_classes=['cocoa', 'invalid']\n",
    "\n",
    "metadata = MetadataCatalog.get(\"fiftyone_train\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dicts = get_fiftyone_dicts(dataset.match_tags(\"train\"))\n",
    "ids = [dd[\"image_id\"] for dd in dataset_dicts]\n",
    "\n",
    "view = dataset.select(ids)\n",
    "session = fo.launch_app(view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.freeze()  # screenshot the App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_count = view.count_values(\"ground_truth.detections.label\")\n",
    "print(label_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.engine import DefaultTrainer\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.OUTPUT_DIR = \"detectron_files/models\"\n",
    "#cfg.merge_from_file(model_zoo.get_config_file(\"\"))\n",
    "cfg.DATASETS.TRAIN = (\"fiftyone_train\",)\n",
    "cfg.DATASETS.TEST = ()\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.TEST.EVAL_PERIOD = 1000\n",
    "#cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"\")  # Let training initialize from model zoo\n",
    "cfg.SOLVER.IMS_PER_BATCH = 4  # This is the real \"batch size\" commonly known to deep learning people\n",
    "cfg.SOLVER.BASE_LR = 0.00001  # pick a good LR\n",
    "cfg.SOLVER.MAX_ITER = 10000    # 300 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset\n",
    "cfg.SOLVER.STEPS = [] # do not decay learning rate\n",
    "cfg.SOLVER.AMP.ENABLED = True        \n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 64  # The \"RoIHead batch size\". 128 is faster, and good enough for this toy dataset (default: 512)\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 2  # only has one class (Vehicle registration plate). (see https://detectron2.readthedocs.io/tutorials/datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.evaluation import COCOEvaluator\n",
    "\n",
    "class CocoTrainer(DefaultTrainer):\n",
    "\n",
    "  @classmethod\n",
    "  def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "\n",
    "    if output_folder is None:\n",
    "        os.makedirs(\"coco_eval\", exist_ok=True)\n",
    "        output_folder = \"coco_eval\"\n",
    "\n",
    "    return COCOEvaluator(dataset_name, cfg, False, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/17 20:57:18 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): ResNet(\n",
      "    (stem): BasicStem(\n",
      "      (conv1): Conv2d(\n",
      "        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "      )\n",
      "    )\n",
      "    (res2): Sequential(\n",
      "      (0): BottleneckBlock(\n",
      "        (shortcut): Conv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv1): Conv2d(\n",
      "          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (2): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (res3): Sequential(\n",
      "      (0): BottleneckBlock(\n",
      "        (shortcut): Conv2d(\n",
      "          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv1): Conv2d(\n",
      "          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (2): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (3): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (res4): Sequential(\n",
      "      (0): BottleneckBlock(\n",
      "        (shortcut): Conv2d(\n",
      "          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "        (conv1): Conv2d(\n",
      "          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (2): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (3): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (4): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (5): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): Res5ROIHeads(\n",
      "    (pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (res5): Sequential(\n",
      "      (0): BottleneckBlock(\n",
      "        (shortcut): Conv2d(\n",
      "          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "        )\n",
      "        (conv1): Conv2d(\n",
      "          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (2): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=2048, out_features=3, bias=True)\n",
      "      (bbox_pred): Linear(in_features=2048, out_features=8, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[01/17 20:57:20 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 86 images left.\n",
      "\u001b[32m[01/17 20:57:20 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(800,), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[01/17 20:57:20 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[01/17 20:57:20 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[01/17 20:57:20 d2.data.common]: \u001b[0mSerializing 86 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/17 20:57:20 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n",
      "\u001b[32m[01/17 20:57:20 d2.data.build]: \u001b[0mMaking batched data loader with batch_size=4\n",
      "\u001b[32m[01/17 20:57:20 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from  ...\n",
      "\u001b[32m[01/17 20:57:20 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paineni/micromamba/envs/Thesis-env/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/17 20:57:28 d2.utils.events]: \u001b[0m eta: 0:55:25  iter: 19  total_loss: 832.2  loss_cls: 277.7  loss_box_reg: 375.2  loss_rpn_cls: 84.25  loss_rpn_loc: 85.15    time: 0.3588  last_time: 0.3971  data_time: 0.0207  last_data_time: 0.0080   lr: 1.9981e-07  max_mem: 4007M\n",
      "\u001b[32m[01/17 20:57:39 d2.utils.events]: \u001b[0m eta: 1:16:40  iter: 39  total_loss: 260.1  loss_cls: 176.2  loss_box_reg: 61.44  loss_rpn_cls: 7.111  loss_rpn_loc: 18.38    time: 0.4552  last_time: 0.5646  data_time: 0.0083  last_data_time: 0.0073   lr: 3.9961e-07  max_mem: 4007M\n",
      "\u001b[32m[01/17 20:57:50 d2.utils.events]: \u001b[0m eta: 1:33:46  iter: 59  total_loss: 46.21  loss_cls: 22.79  loss_box_reg: 9.357  loss_rpn_cls: 1.579  loss_rpn_loc: 9.947    time: 0.4947  last_time: 0.5679  data_time: 0.0076  last_data_time: 0.0070   lr: 5.9941e-07  max_mem: 4007M\n",
      "\u001b[32m[01/17 20:58:02 d2.utils.events]: \u001b[0m eta: 1:34:03  iter: 79  total_loss: 16.42  loss_cls: 4.638  loss_box_reg: 2.466  loss_rpn_cls: 1.053  loss_rpn_loc: 7.786    time: 0.5154  last_time: 0.5767  data_time: 0.0077  last_data_time: 0.0080   lr: 7.9921e-07  max_mem: 4007M\n",
      "\u001b[32m[01/17 20:58:13 d2.engine.hooks]: \u001b[0mOverall training speed: 96 iterations in 0:00:51 (0.5316 s / it)\n",
      "\u001b[32m[01/17 20:58:13 d2.engine.hooks]: \u001b[0mTotal training time: 0:00:51 (0:00:00 on hooks)\n",
      "\u001b[32m[01/17 20:58:13 d2.utils.events]: \u001b[0m eta: 1:34:11  iter: 98  total_loss: 14.67  loss_cls: 2.032  loss_box_reg: 4.155  loss_rpn_cls: 0.822  loss_rpn_loc: 7.004    time: 0.5266  last_time: 0.5742  data_time: 0.0072  last_data_time: 0.0069   lr: 9.7903e-07  max_mem: 4007M\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m trainer \u001b[39m=\u001b[39m DefaultTrainer(cfg)\n\u001b[1;32m      6\u001b[0m trainer\u001b[39m.\u001b[39mresume_or_load(resume\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m----> 7\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[0;32m~/micromamba/envs/Thesis-env/lib/python3.11/site-packages/detectron2/engine/defaults.py:486\u001b[0m, in \u001b[0;36mDefaultTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    479\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    480\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    481\u001b[0m \u001b[39m    Run training.\u001b[39;00m\n\u001b[1;32m    482\u001b[0m \n\u001b[1;32m    483\u001b[0m \u001b[39m    Returns:\u001b[39;00m\n\u001b[1;32m    484\u001b[0m \u001b[39m        OrderedDict of results, if evaluation is enabled. Otherwise None.\u001b[39;00m\n\u001b[1;32m    485\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 486\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mtrain(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstart_iter, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_iter)\n\u001b[1;32m    487\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcfg\u001b[39m.\u001b[39mTEST\u001b[39m.\u001b[39mEXPECTED_RESULTS) \u001b[39mand\u001b[39;00m comm\u001b[39m.\u001b[39mis_main_process():\n\u001b[1;32m    488\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mhasattr\u001b[39m(\n\u001b[1;32m    489\u001b[0m             \u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m_last_eval_results\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    490\u001b[0m         ), \u001b[39m\"\u001b[39m\u001b[39mNo evaluation results obtained during training!\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/micromamba/envs/Thesis-env/lib/python3.11/site-packages/detectron2/engine/train_loop.py:155\u001b[0m, in \u001b[0;36mTrainerBase.train\u001b[0;34m(self, start_iter, max_iter)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[39mfor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miter \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(start_iter, max_iter):\n\u001b[1;32m    154\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbefore_step()\n\u001b[0;32m--> 155\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_step()\n\u001b[1;32m    156\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mafter_step()\n\u001b[1;32m    157\u001b[0m \u001b[39m# self.iter == max_iter can be used by `after_train` to\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[39m# tell whether the training successfully finished or failed\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[39m# due to exceptions.\u001b[39;00m\n",
      "File \u001b[0;32m~/micromamba/envs/Thesis-env/lib/python3.11/site-packages/detectron2/engine/defaults.py:496\u001b[0m, in \u001b[0;36mDefaultTrainer.run_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_step\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    495\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_trainer\u001b[39m.\u001b[39miter \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miter\n\u001b[0;32m--> 496\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_trainer\u001b[39m.\u001b[39;49mrun_step()\n",
      "File \u001b[0;32m~/micromamba/envs/Thesis-env/lib/python3.11/site-packages/detectron2/engine/train_loop.py:504\u001b[0m, in \u001b[0;36mAMPTrainer.run_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mzero_grad_before_forward:\n\u001b[1;32m    502\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m--> 504\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgrad_scaler\u001b[39m.\u001b[39;49mscale(losses)\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m    506\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog_grad_scaler:\n\u001b[1;32m    507\u001b[0m     storage \u001b[39m=\u001b[39m get_event_storage()\n",
      "File \u001b[0;32m~/micromamba/envs/Thesis-env/lib/python3.11/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    493\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    494\u001b[0m )\n",
      "File \u001b[0;32m~/micromamba/envs/Thesis-env/lib/python3.11/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[39m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m     tensors,\n\u001b[1;32m    253\u001b[0m     grad_tensors_,\n\u001b[1;32m    254\u001b[0m     retain_graph,\n\u001b[1;32m    255\u001b[0m     create_graph,\n\u001b[1;32m    256\u001b[0m     inputs,\n\u001b[1;32m    257\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    258\u001b[0m     accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    259\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#html#update-the-config-for-new-datasets)\n",
    "# NOTE: this config means the number of classes, but a few popular unofficial tutorials incorrect uses num_classes+1 here.\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = DefaultTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/17 20:47:50 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from detectron_files/models/model_final.pth ...\n"
     ]
    }
   ],
   "source": [
    "# Inference should use the config with parameters that are used in training\n",
    "# cfg now already contains everything we've set previously. We changed it a little bit for inference:\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set a custom testing threshold\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectron_to_fo(outputs, img_w, img_h):\n",
    "    # format is documented at https://detectron2.readthedocs.io/tutorials/models.html#model-output-format\n",
    "    detections = []\n",
    "    instances = outputs[\"instances\"].to(\"cpu\")\n",
    "    for pred_box, score, c in zip(\n",
    "        instances.pred_boxes, instances.scores, instances.pred_classes, \n",
    "    ):\n",
    "        x1, y1, x2, y2 = pred_box\n",
    "        bbox = [float(x1)/img_w, float(y1)/img_h, float(x2-x1)/img_w, float(y2-y1)/img_h]\n",
    "        detection = fo.Detection(label=dataset.default_classes[c], confidence=float(score), bounding_box=bbox, )\n",
    "        detections.append(detection)\n",
    "\n",
    "    return fo.Detections(detections=detections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in dataset:\n",
    "    img_w = sample.metadata[\"width\"]\n",
    "    img_h = sample.metadata[\"height\"]\n",
    "    img = cv2.imread(sample[\"filepath\"])\n",
    "    outputs = predictor(img)\n",
    "    detections = detectron_to_fo(outputs, img_w, img_h)\n",
    "    sample[\"predictions\"] = detections\n",
    "    sample.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(outputs['instances'].pred_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fo.Session(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating detections...\n",
      " 100% |███████████████████| 86/86 [21.6s elapsed, 0s remaining, 4.0 samples/s]      \n",
      "Performing IoU sweep...\n",
      " 100% |███████████████████| 86/86 [14.4s elapsed, 0s remaining, 6.2 samples/s]      \n",
      "mAP@[0.5:0.05:0.95] train : 0.3137940867897281\n",
      "AP@[0.5:0.05:0.95] of train (cocoa): 0.5863435448050294\n",
      "AP@[0.5:0.05:0.95] of train (invalid): 0.041244628774426854\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       cocoa       0.92      0.96      0.94      3714\n",
      "     invalid       0.67      0.19      0.30       586\n",
      "\n",
      "   micro avg       0.91      0.85      0.88      4300\n",
      "   macro avg       0.79      0.57      0.62      4300\n",
      "weighted avg       0.88      0.85      0.85      4300\n",
      "\n",
      "TP (train): 3664\n",
      "FP (train): 372\n",
      "FN (train): 636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_992051/3278831308.py:40: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  classwise_ap_df = classwise_ap_df._append(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating detections...\n",
      " 100% |███████████████████| 22/22 [5.5s elapsed, 0s remaining, 3.9 samples/s]      \n",
      "Performing IoU sweep...\n",
      " 100% |███████████████████| 22/22 [3.8s elapsed, 0s remaining, 5.1 samples/s]      \n",
      "mAP@[0.5:0.05:0.95] valid : 0.2907385663692545\n",
      "AP@[0.5:0.05:0.95] of valid (cocoa): 0.5618770789468348\n",
      "AP@[0.5:0.05:0.95] of valid (invalid): 0.019600053791674177\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       cocoa       0.92      0.94      0.93       963\n",
      "     invalid       0.40      0.13      0.20       137\n",
      "\n",
      "   micro avg       0.90      0.84      0.87      1100\n",
      "   macro avg       0.66      0.54      0.57      1100\n",
      "weighted avg       0.86      0.84      0.84      1100\n",
      "\n",
      "TP (valid): 928\n",
      "FP (valid): 102\n",
      "FN (valid): 172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_992051/3278831308.py:40: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  classwise_ap_df = classwise_ap_df._append(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating detections...\n",
      " 100% |███████████████████| 12/12 [2.9s elapsed, 0s remaining, 4.1 samples/s]      \n",
      "Performing IoU sweep...\n",
      " 100% |███████████████████| 12/12 [1.9s elapsed, 0s remaining, 6.2 samples/s]         \n",
      "mAP@[0.5:0.05:0.95] test : 0.27768122652848776\n",
      "AP@[0.5:0.05:0.95] of test (cocoa): 0.5434246878518836\n",
      "AP@[0.5:0.05:0.95] of test (invalid): 0.011937765205091938\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       cocoa       0.93      0.93      0.93       537\n",
      "     invalid       0.36      0.08      0.13        63\n",
      "\n",
      "   micro avg       0.91      0.84      0.87       600\n",
      "   macro avg       0.64      0.50      0.53       600\n",
      "weighted avg       0.87      0.84      0.84       600\n",
      "\n",
      "TP (test): 503\n",
      "FP (test): 48\n",
      "FN (test): 97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_992051/3278831308.py:40: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  classwise_ap_df = classwise_ap_df._append(\n"
     ]
    }
   ],
   "source": [
    "splits = ['train','valid','test']\n",
    "for split_tag in splits:\n",
    "    view = dataset.match_tags([split_tag])\n",
    "\n",
    "    # Evaluate the objects in the `predictions`\n",
    "    # field with respect to the\n",
    "    # objects in the `ground_truth` field\n",
    "    eval_key = f\"eval_predictions_{split_tag}\"\n",
    "    results = view.evaluate_detections(\n",
    "        \"predictions\",\n",
    "        gt_field=\"ground_truth\",\n",
    "        eval_key=eval_key,\n",
    "        compute_mAP=True,\n",
    "        classes=dataset.default_classes,\n",
    "        missing=\"background\",\n",
    "        classwise=True,\n",
    "    )\n",
    "    # whether to consider objects with different label\n",
    "    # values as always non-overlapping (True) or to compute IoUs\n",
    "    # for all objects regardless of label (False)\n",
    "\n",
    "    # the COCO mAP evaluator averages the mAP\n",
    "    # over 10 IoU thresholds from 0.5 to 0.95\n",
    "    # with a step size of 0.05 (AP@[0.5:0.05:0.95])\n",
    "    # To be found in the source of fiftyone.\n",
    "    # \"https://github.com/voxel51/fiftyone/blob/\"\n",
    "    # \"acf3a8f886505d852903e320d057057813261993/fiftyone/\"\n",
    "    # \"utils/eval/coco.py#L91\"\n",
    "    mAP = results.mAP()\n",
    "    print(f\"mAP@[0.5:0.05:0.95] {split_tag} : \" + str(mAP))\n",
    "    classwise_ap_df = pd.DataFrame(\n",
    "        columns=[\"Label\", \"AP@[0.5:0.05:0.95]\"]\n",
    "    )\n",
    "    for label in dataset.default_classes:\n",
    "        class_AP = results.mAP([label])\n",
    "        print(\n",
    "            f\"AP@[0.5:0.05:0.95] of {split_tag} ({label}): \"\n",
    "            + str(class_AP)\n",
    "        )\n",
    "        classwise_ap_df = classwise_ap_df._append(\n",
    "            {\"Label\": label, \"AP@[0.5:0.05:0.95]\": class_AP},\n",
    "            ignore_index=True,\n",
    "        )\n",
    "\n",
    "    \n",
    "    results.print_report()\n",
    "    report = results.report()\n",
    "    weighted_avg_precision = report[\"weighted avg\"][\"precision\"]\n",
    "    weighted_avg_recall = report[\"weighted avg\"][\"recall\"]\n",
    "    \n",
    "\n",
    "    # Print some statistics about the total TP/FP/FN counts\n",
    "    mean_tp = view.sum(f\"{eval_key}_tp\")\n",
    "    mean_fp = view.sum(f\"{eval_key}_fp\")\n",
    "    mean_fn = view.sum(f\"{eval_key}_fn\")\n",
    "    print(f\"TP ({split_tag}): {mean_tp}\")\n",
    "    print(f\"FP ({split_tag}): {mean_fp}\")\n",
    "    print(f\"FN ({split_tag}): {mean_fn}\")\n",
    "\n",
    "    \n",
    "    # class_counts = view.count_values(\"predictions.detections.label\")\n",
    "\n",
    "    # pr_curve_path = os.path.join(\n",
    "    #     artifacts_path, f\"PR_curve_{split_tag}.png\"\n",
    "    # )\n",
    "    # pr_curve_plot: Figure = results.plot_pr_curves(\n",
    "    #     classes=list(class_counts.keys()),\n",
    "    #     backend=\"matplotlib\",\n",
    "    #     style=\"dark_background\",\n",
    "    # )\n",
    "    # pr_curve_plot.savefig(pr_curve_path, dpi=250)\n",
    "    # mlflow.log_artifact(pr_curve_path)\n",
    "\n",
    "    # conf_mat_path = os.path.join(\n",
    "    #     self.artifacts_path, f\"confusion_matrix_{split_tag}.png\"\n",
    "    # )\n",
    "    # conf_mat_plot: Figure = results.plot_confusion_matrix(\n",
    "    #     backend=\"matplotlib\"\n",
    "    # )\n",
    "    # conf_mat_plot.savefig(conf_mat_path, dpi=250)\n",
    "    # mlflow.log_artifact(conf_mat_path)\n",
    "\n",
    "    # mlflow.end_run()\n",
    "\n",
    "    # return dataset\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
